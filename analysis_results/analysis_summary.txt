СРАВНИТЕЛЬНЫЙ АНАЛИЗ АЛГОРИТМОВ TSP
==================================================

1. ДЛИНА МАРШРУТОВ
--------------------------------------------------
Алгоритм Хелда-Карпа (DP): 371.99
Double Q-learning (RL): 470.30
Абсолютная разница: +98.30
Относительная разница: +26.43%

2. МАРШРУТЫ
--------------------------------------------------
DP: City_0 -> City_17 -> City_9 -> City_8 -> City_5 -> City_12 -> City_13 -> City_20 -> City_6 -> City_18 -> City_2 -> City_3 -> City_11 -> City_16 -> City_15 -> City_10 -> City_1 -> City_4 -> City_7 -> City_14 -> City_19 -> City_0

RL: City_0 -> City_1 -> City_18 -> City_14 -> City_9 -> City_10 -> City_16 -> City_8 -> City_5 -> City_6 -> City_12 -> City_15 -> City_13 -> City_19 -> City_4 -> City_11 -> City_7 -> City_17 -> City_3 -> City_2 -> City_0

3. ОБЩИЕ ПОДПОСЛЕДОВАТЕЛЬНОСТИ
--------------------------------------------------
Подпоследовательность 1: City_8 -> City_5 -> City_5

4. ВЫВОДЫ
--------------------------------------------------
- Алгоритм Хелда-Карпа находит оптимальный маршрут с меньшей общей длиной.
- Double Q-learning находит приближенное решение, которое длиннее оптимального на 26.43%.
- Преимуществом RL-подхода является возможность работы с большим количеством городов.
- Качество решения RL-алгоритма можно улучшить, увеличив количество эпизодов обучения.
