# Компонент обучения с подкреплением (RL)

Данный компонент реализует решение задачи коммивояжера (TSP) с использованием метода обучения с подкреплением, а именно алгоритма Double Q-learning.

## Структура директории

```
RL_part/
├── rl_environment/          # Модули для работы со средой
│   └── generate_env.py      # Скрипт для генерации тестовой среды
├── double_q_learning.py     # Основная реализация алгоритма Double Q-learning
├── predict_route.py         # Модуль для прогнозирования маршрута с обученными весами
├── rl_api.py                # API для работы с алгоритмом через REST
├── runs/                    # Директория для хранения результатов обучения
│   └── test_3/              # Пример сохраненного обучения (используется по умолчанию)
│       ├── q1_weights.txt   # Веса первой Q-таблицы
│       ├── q2_weights.txt   # Веса второй Q-таблицы
│       └── best_route.txt   # Лучший найденный маршрут
└── tests/                   # Тестовые данные
    └── test_*/              # Поддиректории с тестовыми сценариями
        ├── cities.csv       # Координаты городов
        ├── distances.csv    # Матрица расстояний между городами
        ├── best_route.txt   # Лучший найденный маршрут при обучении
        └── predicted_route.txt  # Прогнозируемый маршрут
```

## Алгоритм Double Q-learning

Double Q-learning — это улучшенная версия алгоритма Q-learning для обучения с подкреплением, которая использует две независимые Q-таблицы для уменьшения переоценки значений Q-функции.

### Основные характеристики:
- **Временная сложность обучения**: O(k·n²), где k - количество эпизодов, n - количество городов
- **Пространственная сложность**: O(n²)
- **Точность**: Не гарантирует оптимальное решение, но часто находит близкие к оптимальным решения
- **Масштабируемость**: Может работать с большим количеством городов (>20), в отличие от точных алгоритмов

## Использование компонента

### Обучение модели

```bash
python RL_part/double_q_learning.py --save_path path/to/save/model --num_episodes 1000 --alpha 0.1 --gamma 0.9 --epsilon 0.1
```

Параметры:
- `--save_path`: путь для сохранения модели и результатов (должен содержать cities.csv и distances.csv)
- `--weights_path`: (опционально) путь к существующим весам для продолжения обучения
- `--num_episodes`: количество эпизодов обучения (по умолчанию 1000)
- `--alpha`: скорость обучения (по умолчанию 0.1)
- `--gamma`: коэффициент дисконтирования (по умолчанию 0.9)
- `--epsilon`: вероятность случайного действия (по умолчанию 0.1)

### Прогнозирование маршрута

```bash
python RL_part/predict_route.py --weights_path path/to/model --input_path path/to/data --save_path path/to/save/results
```

Параметры:
- `--weights_path`: путь к обученным весам (директория с q1_weights.txt и q2_weights.txt)
- `--input_path`: путь к данным (директория с cities.csv и distances.csv)
- `--save_path`: путь для сохранения результатов
- `--csv`: флаг, указывающий на использование CSV-файлов (по умолчанию True)

### Запуск API-сервера

```bash
python RL_part/rl_api.py
```

API-сервер запускается на порту 8001 и предоставляет REST API для решения задачи коммивояжера методом обучения с подкреплением.

#### Пример запроса к API:

```bash
curl -X POST http://localhost:8001/solve \
  -H "Content-Type: application/json" \
  -d '{"distance_matrix": [[0, 10, 15, 20], [10, 0, 35, 25], [15, 35, 0, 30], [20, 25, 30, 0]]}'
```

Также можно указать путь к весам в запросе:

```bash
curl -X POST http://localhost:8001/solve \
  -H "Content-Type: application/json" \
  -d '{"distance_matrix": [[0, 10, 15, 20], [10, 0, 35, 25], [15, 35, 0, 30], [20, 25, 30, 0]], "weights_path": "runs/test_3"}'
```

## Генерация тестовых данных

Для создания новых тестовых наборов данных используйте скрипт generate_env.py:

```bash
python RL_part/rl_environment/generate_env.py --num_cities 15 --save_path RL_part/tests/test_new
```

Параметры:
- `--num_cities`: количество городов в тестовом наборе
- `--save_path`: путь для сохранения сгенерированных файлов

## Особенности и преимущества

1. **Масштабируемость**: Метод может работать с большим количеством городов, когда точные алгоритмы становятся непрактичными.

2. **Время выполнения**: После обучения, прогнозирование маршрута выполняется очень быстро (почти мгновенно).

3. **Компромисс качества**: Находит приближенные решения, которые обычно на 10-25% хуже оптимальных, но работает со значительно большими задачами.

4. **Обучение переносится**: Обученные веса могут использоваться для решения новых задач с тем же количеством городов.

## Зависимости

- numpy
- pandas
- matplotlib (для визуализации)
- fastapi (для API)
- uvicorn (для запуска API-сервера)